{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8a3fe",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Gerador CLEVR simplificado (25 objetos) + plot\n",
    "Formato do vetor de cada objeto: [x, y, r, g, b, circle, square, cylinder, cone, triangle, size_scalar] com size em [0,1]. Classes de tamanho: small (<1/3), medium (entre), big (>2/3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SHAPES = [\"circle\", \"square\", \"cylinder\", \"cone\", \"triangle\"]\n",
    "COLORS = [\"red\", \"green\", \"blue\"]\n",
    "SIZE_CLASSES = [\"small\", \"medium\", \"big\"]\n",
    "RELATIONAL_PREDICATES = [\"left\", \"right\", \"below\", \"above\", \"close\", \"can_stack\"]\n",
    "\n",
    "MARKERS = {\"circle\": \"o\", \"square\": \"s\", \"cylinder\": \"P\", \"cone\": \"v\", \"triangle\": \"^\"}\n",
    "COLOR_MAP = {\"red\": \"red\", \"green\": \"green\", \"blue\": \"blue\"}\n",
    "SIZE_MARKER_SCALE = {0: 60, 1: 95, 2: 130}\n",
    "\n",
    "\n",
    "def size_class_from_scalar(s):\n",
    "    # small < 1/3, big > 2/3, medium otherwise\n",
    "    return np.digitize(s, [1/3, 2/3])\n",
    "\n",
    "\n",
    "def generate_scene(n_objects: int = 25, seed: int = 0, eps: float = 0.02):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    coords = rng.random((n_objects, 2))\n",
    "    color_idx = rng.integers(0, len(COLORS), size=n_objects)\n",
    "    shape_idx = rng.integers(0, len(SHAPES), size=n_objects)\n",
    "    size_scalar = rng.random(n_objects)  # continuo em [0,1]\n",
    "    size_idx = size_class_from_scalar(size_scalar)\n",
    "\n",
    "    feats = np.zeros((n_objects, 11), dtype=np.float32)\n",
    "    feats[:, 0:2] = coords\n",
    "    feats[np.arange(n_objects), 2 + color_idx] = 1\n",
    "    feats[np.arange(n_objects), 5 + shape_idx] = 1\n",
    "    feats[:, 10] = size_scalar.astype(np.float32)\n",
    "\n",
    "    feats_t = torch.tensor(feats, device=device)\n",
    "    x = feats_t[:, 0]\n",
    "    y = feats_t[:, 1]\n",
    "    s = feats_t[:, 10]\n",
    "\n",
    "    left = (x[:, None] + eps < x[None, :]).float()\n",
    "    right = (x[:, None] > x[None, :] + eps).float()\n",
    "    below = (y[:, None] + eps < y[None, :]).float()\n",
    "    above = (y[:, None] > y[None, :] + eps).float()\n",
    "\n",
    "    dist2 = (x[:, None] - x[None, :]) ** 2 + (y[:, None] - y[None, :]) ** 2\n",
    "    close = torch.exp(-2 * dist2)\n",
    "\n",
    "    in_between = (\n",
    "        ((x[None, None, :] < x[:, None, None]) & (x[:, None, None] < x[None, :, None]))\n",
    "        | ((x[None, :, None] < x[:, None, None]) & (x[:, None, None] < x[None, None, :]))\n",
    "    ).float()\n",
    "\n",
    "    stable = (torch.abs(x[:, None] - x[None, :]) <= 0.1) | (torch.abs(s[:, None] - s[None, :]) <= 0.15)\n",
    "    can_stack = ((1 - feats_t[:, 5 + 3][:, None]) * (1 - feats_t[:, 5 + 4][:, None]) * stable.float()).float()\n",
    "\n",
    "    labels = {\n",
    "        **{sname: torch.tensor((size_idx == i).astype(np.float32), device=device) for i, sname in enumerate(SIZE_CLASSES)},\n",
    "        **{s: torch.tensor((shape_idx == i).astype(np.float32), device=device) for i, s in enumerate(SHAPES)},\n",
    "        **{c: torch.tensor((color_idx == i).astype(np.float32), device=device) for i, c in enumerate(COLORS)},\n",
    "        \"left\": left,\n",
    "        \"right\": right,\n",
    "        \"below\": below,\n",
    "        \"above\": above,\n",
    "        \"close\": close,\n",
    "        \"in_between\": in_between,\n",
    "        \"can_stack\": can_stack,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"features\": feats_t,\n",
    "        \"labels\": labels,\n",
    "        \"coords\": coords,\n",
    "        \"color_idx\": color_idx,\n",
    "        \"shape_idx\": shape_idx,\n",
    "        \"size_scalar\": size_scalar,\n",
    "        \"size_idx\": size_idx,\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_scene(scene):\n",
    "    coords = scene[\"coords\"]\n",
    "    shapes = scene[\"shape_idx\"]\n",
    "    colors = scene[\"color_idx\"]\n",
    "    sizes = scene[\"size_idx\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    for i, (x, y) in enumerate(coords):\n",
    "        shape_name = SHAPES[shapes[i]]\n",
    "        color_name = COLORS[colors[i]]\n",
    "        marker = MARKERS[shape_name]\n",
    "        size = SIZE_MARKER_SCALE.get(sizes[i], 90)\n",
    "        ax.scatter(x, y, c=COLOR_MAP[color_name], marker=marker, s=size, edgecolor=\"black\", alpha=0.85)\n",
    "        ax.text(x + 0.01, y + 0.01, str(i), fontsize=8)\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(\"Cena CLEVR simplificada (3 tamanhos)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6f189",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Conectivos e quantificadores fuzzy (LTN)\n",
    "Usamos t-norm produto, t-conorm prob-sum, implicacao de Reichenbach e quantificadores por media (Forall) e max (Exists). \balanced_equiv evita desbalanceamento de classes nos fatos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "not_op = lambda x: 1 - x\n",
    "\n",
    "\n",
    "def and_op(*xs):\n",
    "    out = xs[0]\n",
    "    for x in xs[1:]:\n",
    "        out = out * x\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "\n",
    "def or_op(*xs):\n",
    "    out = xs[0]\n",
    "    for x in xs[1:]:\n",
    "        out = out + x - out * x\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "\n",
    "def impl(a, b):\n",
    "    return (1 - a + a * b).clamp(0, 1)\n",
    "\n",
    "\n",
    "def equiv(a, b):\n",
    "    return (1 - torch.abs(a - b)).clamp(0, 1)\n",
    "\n",
    "\n",
    "def forall(x, dim=None):\n",
    "    return x.mean() if dim is None else x.mean(dim=dim)\n",
    "\n",
    "\n",
    "def exists(x, dim=None):\n",
    "    return x.max() if dim is None else x.max(dim=dim).values\n",
    "\n",
    "\n",
    "def prob_or(x, dim):\n",
    "    return 1 - torch.prod(1 - x, dim=dim)\n",
    "\n",
    "\n",
    "def balanced_equiv(pred, target):\n",
    "    pred = pred.flatten()\n",
    "    target = target.flatten()\n",
    "    pos = target > 0.5\n",
    "    neg = ~pos\n",
    "    scores = []\n",
    "    if pos.any():\n",
    "        scores.append(equiv(pred[pos], target[pos]).mean())\n",
    "    if neg.any():\n",
    "        scores.append(equiv(pred[neg], target[neg]).mean())\n",
    "    return torch.stack(scores).mean() if scores else torch.tensor(1.0, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2ab47",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Predicados neurais (LTN em PyTorch)\n",
    "MLPs simples (sigmoide) para predicados unarios e binarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7933644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnaryPredicate(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "\n",
    "class BinaryPredicate(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_dim, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "\n",
    "def build_models():\n",
    "    models = {s: UnaryPredicate(11).to(device) for s in SHAPES}\n",
    "    models.update({c: UnaryPredicate(11).to(device) for c in COLORS})\n",
    "    models.update({sname: UnaryPredicate(11).to(device) for sname in SIZE_CLASSES})\n",
    "    for rel in RELATIONAL_PREDICATES:\n",
    "        models[rel] = BinaryPredicate(22).to(device)\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d6a9d",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Forward de predicados, formulas (axiomas) e consultas da Tarefa 4\n",
    "Inclui: unicidade/cobertura de forma, 3 tamanhos (small/medium/big), regras de left/right, below/above, closeTo, inBetween, lastOnTheLeft/right, canStack, restricao trios proximos = mesmo tamanho, opcionais e consultas compostas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_WEIGHTS = {\n",
    "    \"fact_left\": 4.0,\n",
    "    \"fact_right\": 4.0,\n",
    "    \"fact_below\": 4.0,\n",
    "    \"fact_above\": 4.0,\n",
    "    \"fact_close\": 2.0,\n",
    "    \"fact_can_stack\": 2.0,\n",
    "    \"fact_unary\": 1.0,\n",
    "    \"left_irreflexive\": 2.0,\n",
    "    \"left_asym\": 2.0,\n",
    "    \"left_inverse\": 2.0,\n",
    "    \"left_trans\": 3.0,\n",
    "    \"below_inverse\": 2.0,\n",
    "    \"below_trans\": 3.0,\n",
    "    \"in_between_rule\": 3.0,\n",
    "    \"tri_close_same_size\": 2.0,\n",
    "    \"square_right_circle\": 1.5,\n",
    "    \"exists_left_of_all_squares\": 1.5,\n",
    "}\n",
    "\n",
    "\n",
    "def forward_preds(models, scene):\n",
    "    feat = scene[\"features\"]\n",
    "    n = feat.shape[0]\n",
    "    preds = {k: m(feat) for k, m in models.items() if k not in RELATIONAL_PREDICATES}\n",
    "\n",
    "    pair_feat = torch.cat(\n",
    "        [feat.unsqueeze(1).expand(n, n, -1), feat.unsqueeze(0).expand(n, n, -1)], dim=-1\n",
    "    ).reshape(n * n, -1)\n",
    "    for rel in RELATIONAL_PREDICATES:\n",
    "        preds[rel] = models[rel](pair_feat).reshape(n, n)\n",
    "\n",
    "    L = preds[\"left\"]\n",
    "    R = preds[\"right\"]\n",
    "    preds[\"in_between_pred\"] = or_op(L.T.unsqueeze(2) * R.T.unsqueeze(1), L.T.unsqueeze(1) * R.T.unsqueeze(2))\n",
    "\n",
    "    # tamanho continuo soft (0 small, 0.5 medium, 1 big)\n",
    "    preds[\"size_soft\"] = 0.0 * preds[\"small\"] + 0.5 * preds[\"medium\"] + 1.0 * preds[\"big\"]\n",
    "    preds[\"same_size\"] = 1 - torch.abs(preds[\"size_soft\"].unsqueeze(1) - preds[\"size_soft\"].unsqueeze(0))\n",
    "    return preds\n",
    "\n",
    "\n",
    "def compute_formulas(models, scene):\n",
    "    labels = scene[\"labels\"]\n",
    "    preds = forward_preds(models, scene)\n",
    "    forms = {}\n",
    "    weights = {}\n",
    "\n",
    "    # Fatos unarios (formas, cores, tamanhos)\n",
    "    for name in SHAPES + COLORS + SIZE_CLASSES:\n",
    "        forms[f\"fact_{name}\"] = balanced_equiv(preds[name], labels[name])\n",
    "        weights[f\"fact_{name}\"] = DEFAULT_WEIGHTS[\"fact_unary\"]\n",
    "\n",
    "    # Fatos binarios\n",
    "    for rel in RELATIONAL_PREDICATES:\n",
    "        forms[f\"fact_{rel}\"] = balanced_equiv(preds[rel], labels[rel])\n",
    "        key = f\"fact_{rel}\"\n",
    "        weights[key] = DEFAULT_WEIGHTS.get(key, DEFAULT_WEIGHTS[\"fact_close\"] if rel == \"close\" else DEFAULT_WEIGHTS[\"fact_can_stack\"])\n",
    "\n",
    "    # Unicidade e cobertura de forma\n",
    "    spreds = torch.stack([preds[s] for s in SHAPES], dim=-1)\n",
    "    prod_pairs = torch.matmul(spreds.unsqueeze(2), spreds.unsqueeze(1))\n",
    "    mask = 1 - torch.eye(len(SHAPES), device=device)\n",
    "    clash = (prod_pairs * mask).max(dim=-1).values\n",
    "    forms[\"unique_shape\"] = forall(not_op(clash))\n",
    "    weights[\"unique_shape\"] = 1.0\n",
    "    forms[\"coverage_shape\"] = forall(prob_or(spreds, dim=-1))\n",
    "    weights[\"coverage_shape\"] = 1.0\n",
    "\n",
    "    # Exclusividade e cobertura de tamanho (small/medium/big)\n",
    "    tpreds = torch.stack([preds[s] for s in SIZE_CLASSES], dim=-1)\n",
    "    tprod_pairs = torch.matmul(tpreds.unsqueeze(2), tpreds.unsqueeze(1))\n",
    "    tmask = 1 - torch.eye(len(SIZE_CLASSES), device=device)\n",
    "    tclash = (tprod_pairs * tmask).max(dim=-1).values\n",
    "    forms[\"size_exclusive\"] = forall(not_op(tclash))\n",
    "    weights[\"size_exclusive\"] = 1.0\n",
    "    forms[\"size_coverage\"] = forall(prob_or(tpreds, dim=-1))\n",
    "    weights[\"size_coverage\"] = 1.0\n",
    "\n",
    "    # Regras de Left/Right\n",
    "    L = preds[\"left\"]\n",
    "    R = preds[\"right\"]\n",
    "    forms[\"left_irreflexive\"] = forall(not_op(torch.diag(L)))\n",
    "    weights[\"left_irreflexive\"] = DEFAULT_WEIGHTS[\"left_irreflexive\"]\n",
    "    forms[\"left_asym\"] = forall(impl(L, not_op(L.T)))\n",
    "    weights[\"left_asym\"] = DEFAULT_WEIGHTS[\"left_asym\"]\n",
    "    forms[\"left_inverse\"] = forall(equiv(L, R.T))\n",
    "    weights[\"left_inverse\"] = DEFAULT_WEIGHTS[\"left_inverse\"]\n",
    "    lhs_trans = L.unsqueeze(2) * L.unsqueeze(0)\n",
    "    forms[\"left_trans\"] = forall(impl(lhs_trans, L.unsqueeze(1)))\n",
    "    weights[\"left_trans\"] = DEFAULT_WEIGHTS[\"left_trans\"]\n",
    "\n",
    "    # Regras abaixo/acima\n",
    "    B = preds[\"below\"]\n",
    "    A = preds[\"above\"]\n",
    "    forms[\"below_inverse\"] = forall(equiv(B, A.T))\n",
    "    weights[\"below_inverse\"] = DEFAULT_WEIGHTS[\"below_inverse\"]\n",
    "    lhs_btrans = B.unsqueeze(2) * B.unsqueeze(0)\n",
    "    forms[\"below_trans\"] = forall(impl(lhs_btrans, B.unsqueeze(1)))\n",
    "    weights[\"below_trans\"] = DEFAULT_WEIGHTS[\"below_trans\"]\n",
    "\n",
    "    # inBetween (definido por left/right)\n",
    "    forms[\"in_between_rule\"] = forall(equiv(preds[\"in_between_pred\"], labels[\"in_between\"]))\n",
    "    weights[\"in_between_rule\"] = DEFAULT_WEIGHTS[\"in_between_rule\"]\n",
    "\n",
    "    # Triangulos proximos => mesmo tamanho (usando size_soft)\n",
    "    tri_mask = preds[\"triangle\"].unsqueeze(1) * preds[\"triangle\"].unsqueeze(0)\n",
    "    forms[\"tri_close_same_size\"] = forall(impl(tri_mask * preds[\"close\"], preds[\"same_size\"]))\n",
    "    weights[\"tri_close_same_size\"] = DEFAULT_WEIGHTS[\"tri_close_same_size\"]\n",
    "\n",
    "    # Opcional: quadrados a direita de circulos\n",
    "    forms[\"square_right_circle\"] = forall(impl(preds[\"square\"].unsqueeze(1) * preds[\"circle\"].unsqueeze(0), R))\n",
    "    weights[\"square_right_circle\"] = DEFAULT_WEIGHTS[\"square_right_circle\"]\n",
    "\n",
    "    # Opcional: existe alguem a esquerda de todos os quadrados\n",
    "    per_x = forall(impl(preds[\"square\"].unsqueeze(0), L), dim=1)\n",
    "    forms[\"exists_left_of_all_squares\"] = exists(per_x)\n",
    "    weights[\"exists_left_of_all_squares\"] = DEFAULT_WEIGHTS[\"exists_left_of_all_squares\"]\n",
    "\n",
    "    sat = sum(weights[k] * v for k, v in forms.items()) / sum(weights.values())\n",
    "    return sat, forms, preds\n",
    "\n",
    "\n",
    "def composed_queries(preds):\n",
    "    small = preds[\"small\"]\n",
    "    cylinder = preds[\"cylinder\"]\n",
    "    square = preds[\"square\"]\n",
    "    left = preds[\"left\"]\n",
    "    below = preds[\"below\"]\n",
    "    cone = preds[\"cone\"]\n",
    "    green = preds[\"green\"]\n",
    "    in_between_pred = preds[\"in_between_pred\"]\n",
    "\n",
    "    below_target = exists(and_op(cylinder.unsqueeze(0), below), dim=1)\n",
    "    left_target = exists(and_op(square.unsqueeze(0), left), dim=1)\n",
    "    q1 = exists(and_op(small, below_target, left_target))\n",
    "\n",
    "    cone_green = cone * green\n",
    "    q2 = exists(cone_green.unsqueeze(1).unsqueeze(2) * in_between_pred)\n",
    "\n",
    "    return {\n",
    "        \"q1_small_below_left\": q1,\n",
    "        \"q2_green_cone_between\": q2,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9c096",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Treino, metricas e explicacoes (questao extra)\n",
    "Treinamos maximizando satAgg ponderado. Metricas binarias (acc, precisao, recall, F1) por predicado e satisfacao de cada formula. Explicacoes textuais para Q1/Q2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESH = 0.5  # limiar padrao para metricas/explicacoes\n",
    "\n",
    "\n",
    "def train_scene(scene, epochs: int = 250, lr: float = 0.01):\n",
    "    models = build_models()\n",
    "    opt = torch.optim.Adam([p for m in models.values() for p in m.parameters()], lr=lr)\n",
    "    history = []\n",
    "    final_forms = None\n",
    "    final_preds = None\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        sat, forms, preds = compute_formulas(models, scene)\n",
    "        loss = 1 - sat\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        history.append(sat.item())\n",
    "        final_forms, final_preds = forms, preds\n",
    "\n",
    "    return models, history, final_forms, final_preds\n",
    "\n",
    "\n",
    "def _metrics_one(name, pred, target, threshold=THRESH):\n",
    "    pred_b = (pred.detach().cpu().numpy().flatten() >= threshold).astype(int)\n",
    "    tgt_b = (target.detach().cpu().numpy().flatten() >= threshold).astype(int)\n",
    "    acc = (pred_b == tgt_b).mean()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(tgt_b, pred_b, average=\"binary\", zero_division=0)\n",
    "    return {\"pred\": name, \"acc\": acc, \"prec\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, threshold=THRESH):\n",
    "    rows = []\n",
    "    for name in SHAPES + COLORS + SIZE_CLASSES:\n",
    "        rows.append(_metrics_one(name, preds[name], labels[name], threshold))\n",
    "    for rel in RELATIONAL_PREDICATES:\n",
    "        rows.append(_metrics_one(rel, preds[rel], labels[rel], threshold))\n",
    "    rows.append(_metrics_one(\"in_between\", preds[\"in_between_pred\"], labels[\"in_between\"], threshold))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def explain_queries(scene, preds, threshold=0.6):\n",
    "    coords = scene[\"coords\"]\n",
    "    small = preds[\"small\"]\n",
    "    cylinder = preds[\"cylinder\"]\n",
    "    square = preds[\"square\"]\n",
    "    left = preds[\"left\"]\n",
    "    below = preds[\"below\"]\n",
    "    cone = preds[\"cone\"]\n",
    "    green = preds[\"green\"]\n",
    "    in_between_pred = preds[\"in_between_pred\"]\n",
    "\n",
    "    below_target = exists(and_op(cylinder.unsqueeze(0), below), dim=1)\n",
    "    left_target = exists(and_op(square.unsqueeze(0), left), dim=1)\n",
    "    q1_strength = small * below_target * left_target\n",
    "    idxs = (q1_strength >= threshold).nonzero().flatten().tolist()\n",
    "    print(f\"Q1 (pequeno, abaixo de cilindro, a esquerda de quadrado) >= {threshold}: {idxs}\")\n",
    "    for idx in idxs[:5]:\n",
    "        print(f\"- obj {idx} coords={coords[idx]} forca={float(q1_strength[idx]):.3f}\")\n",
    "\n",
    "    cone_green = cone * green\n",
    "    triples = cone_green.unsqueeze(1).unsqueeze(2) * in_between_pred\n",
    "    best = torch.argmax(triples).item()\n",
    "    n = in_between_pred.shape[0]\n",
    "    x_idx = best // (n * n)\n",
    "    rem = best % (n * n)\n",
    "    y_idx = rem // n\n",
    "    z_idx = rem % n\n",
    "    print(\"Q2 (cone verde entre dois objetos) melhor tripla:\")\n",
    "    print(f\"- x={x_idx} (cone*verde={float(cone_green[x_idx]):.3f}), y={y_idx}, z={z_idx}, forca={float(triples[x_idx, y_idx, z_idx]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63bcfa",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Execucao exemplo unico (seed=0)\n",
    "Gera cena, plota, treina, mostra satAgg final, metricas, consultas e explicacoes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361da0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene = generate_scene(n_objects=25, seed=0)\n",
    "plot_scene(scene)\n",
    "\n",
    "models, history, forms, preds = train_scene(scene, epochs=220, lr=0.01)\n",
    "print(f\"satAgg final: {history[-1]:.4f}\")\n",
    "\n",
    "metrics_df = compute_metrics(preds, scene[\"labels\"], threshold=THRESH)\n",
    "display(metrics_df)\n",
    "\n",
    "queries = composed_queries(preds)\n",
    "print({k: float(v) for k, v in queries.items()})\n",
    "explain_queries(scene, preds, threshold=0.6)\n",
    "\n",
    "formula_table = pd.DataFrame([{ \"formula\": k, \"satisfacao\": float(v) } for k, v in forms.items()])\n",
    "display(formula_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70452294",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Experimentos 5x (seeds diferentes)\n",
    "Repete geracao + treino para 5 seeds e consolida satAgg e metricas agregadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "for seed in range(5):\n",
    "    scene_i = generate_scene(n_objects=25, seed=seed)\n",
    "    _, hist_i, forms_i, preds_i = train_scene(scene_i, epochs=180, lr=0.01)\n",
    "    metrics_i = compute_metrics(preds_i, scene_i[\"labels\"], threshold=THRESH)\n",
    "    results.append({\n",
    "        \"seed\": seed,\n",
    "        \"satAgg\": hist_i[-1],\n",
    "        \"acc_macro\": metrics_i[\"acc\"].mean(),\n",
    "        \"prec_macro\": metrics_i[\"prec\"].mean(),\n",
    "        \"recall_macro\": metrics_i[\"recall\"].mean(),\n",
    "        \"f1_macro\": metrics_i[\"f1\"].mean(),\n",
    "        \"q1\": float(composed_queries(preds_i)[\"q1_small_below_left\"]),\n",
    "        \"q2\": float(composed_queries(preds_i)[\"q2_green_cone_between\"]),\n",
    "        \"tri_close_same_size\": float(forms_i[\"tri_close_same_size\"]),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f3b4d",
   "metadata": {},
   "source": [
    "\n",
    "## Avaliacao da imagem do grupo\n",
    "Use esta celula para validar o modelo na imagem que o professor avaliara. Ajuste objects_manual com os objetos (grid 0-20) e execute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# One-hot helpers\n",
    "shape_to_vec = {\n",
    "    'circle': [1,0,0,0,0],\n",
    "    'square': [0,1,0,0,0],\n",
    "    'cylinder': [0,0,1,0,0],\n",
    "    'cone': [0,0,0,1,0],\n",
    "    'triangle': [0,0,0,0,1],\n",
    "}\n",
    "color_to_vec = {\n",
    "    'red':   [1,0,0],\n",
    "    'green': [0,1,0],\n",
    "    'blue':  [0,0,1],\n",
    "}\n",
    "\n",
    "def size_class_from_scalar(s):\n",
    "    # small < 1/3, big > 2/3, medium otherwise\n",
    "    return 0 if s <= 1/3 else (2 if s > 2/3 else 1)\n",
    "\n",
    "def build_scene_from_objects(objs, grid_size=20.0, eps=0.02):\n",
    "    rows = []\n",
    "    size_idx = []\n",
    "    shapes_idx = []\n",
    "    colors_idx = []\n",
    "    for _, x, y, color, shape, s_scalar in objs:\n",
    "        xv = x / grid_size\n",
    "        yv = y / grid_size\n",
    "        r,g,b = color_to_vec[color]\n",
    "        shv = shape_to_vec[shape]\n",
    "        rows.append([xv, yv, r, g, b] + shv + [s_scalar])\n",
    "        size_idx.append(size_class_from_scalar(s_scalar))\n",
    "        shapes_idx.append(list(shape_to_vec.keys()).index(shape))\n",
    "        colors_idx.append(list(color_to_vec.keys()).index(color))\n",
    "\n",
    "    feats = torch.tensor(rows, dtype=torch.float32, device=device)\n",
    "    x = feats[:,0]; y = feats[:,1]; s = feats[:,10]\n",
    "\n",
    "    left  = (x[:,None] + eps < x[None,:]).float()\n",
    "    right = (x[:,None] > x[None,:] + eps).float()\n",
    "    below = (y[:,None] + eps < y[None,:]).float()\n",
    "    above = (y[:,None] > y[None,:] + eps).float()\n",
    "    dist2 = (x[:,None]-x[None,:])**2 + (y[:,None]-y[None,:])**2\n",
    "    close = torch.exp(-2*dist2)\n",
    "    in_between = (((x[None,None,:] < x[:,None,None]) & (x[:,None,None] < x[None,:,None])) | ((x[None,:,None] < x[:,None,None]) & (x[:,None,None] < x[None,None,:]))).float()\n",
    "    stable = (torch.abs(x[:,None]-x[None,:])<=0.1) | (torch.abs(s[:,None]-s[None,:])<=0.15)\n",
    "    can_stack = ((1 - feats[:,5+3][:,None]) * (1 - feats[:,5+4][:,None]) * stable.float()).float()\n",
    "\n",
    "    labels = {\n",
    "        'small': torch.tensor([1 if size_class_from_scalar(ss)==0 else 0 for *_, ss in objs], device=device, dtype=torch.float32),\n",
    "        'medium': torch.tensor([1 if size_class_from_scalar(ss)==1 else 0 for *_, ss in objs], device=device, dtype=torch.float32),\n",
    "        'big': torch.tensor([1 if size_class_from_scalar(ss)==2 else 0 for *_, ss in objs], device=device, dtype=torch.float32),\n",
    "    }\n",
    "    for sname in SHAPES:\n",
    "        labels[sname] = torch.tensor([1 if shape==sname else 0 for *_, shape, _ in objs], device=device, dtype=torch.float32)\n",
    "    for cname in COLORS:\n",
    "        labels[cname] = torch.tensor([1 if color==cname else 0 for *_, color, _, _ in objs], device=device, dtype=torch.float32)\n",
    "\n",
    "    labels.update({'left': left, 'right': right, 'below': below, 'above': above,\n",
    "                   'close': close, 'in_between': in_between, 'can_stack': can_stack})\n",
    "\n",
    "    return {\n",
    "        'features': feats,\n",
    "        'labels': labels,\n",
    "        'coords': feats[:,0:2].cpu().numpy(),\n",
    "        'shape_idx': shapes_idx,\n",
    "        'color_idx': colors_idx,\n",
    "        'size_idx': size_idx,\n",
    "    }\n",
    "\n",
    "# Preencha com os objetos da imagem (grid 0-20). Exemplo inicial aproximado:\n",
    "objects_manual = [\n",
    "    ('A1' ,  2 ,  2 , 'green','square'   , 0.85),\n",
    "    ('A14',  5 ,  1 , 'red'  ,'square'   , 0.20),\n",
    "    ('A0' ,  5 ,  4 , 'green','triangle' , 0.50),\n",
    "    ('A13',  8 ,  4 , 'green','square'   , 0.40),\n",
    "    ('A11', 10 ,  5 , 'green','cylinder' , 0.35),\n",
    "    ('A6' ,  8 ,  5 , 'red'  ,'triangle' , 0.30),\n",
    "    ('A4' ,  8 ,  9 , 'blue' ,'triangle' , 0.30),\n",
    "    ('A3' ,  6 ,  9 , 'blue' ,'cylinder' , 0.35),\n",
    "    ('A2' ,  4 , 10 , 'blue' ,'triangle' , 0.85),\n",
    "    ('A5' ,  6 , 12 , 'red'  ,'triangle' , 0.60),\n",
    "    ('A8' , 10 , 10 , 'blue' ,'circle'   , 0.30),\n",
    "    ('A9' , 12 ,  9 , 'red'  ,'circle'   , 0.55),\n",
    "    ('A12', 12 , 11.5,'red'  ,'circle'   , 0.55),\n",
    "    ('A10', 10 , 14 , 'green','cylinder' , 0.85),\n",
    "    ('A15',  4 , 16 , 'green','cone'     , 0.60),\n",
    "    ('A16',  8 , 16 , 'blue' ,'cone'     , 0.60),\n",
    "    ('A18', 10 , 17 , 'green','cone'     , 0.30),\n",
    "    ('A19',  6 , 18 , 'blue' ,'cylinder' , 0.55),\n",
    "    ('A20', 10 , 18 , 'red'  ,'cone'     , 0.30),\n",
    "    ('A21', 13 , 18 , 'red'  ,'cone'     , 0.30),\n",
    "    ('A22', 18 , 18 , 'red'  ,'cylinder' , 0.55),\n",
    "    ('A7' , 16 , 12 , 'green','circle'   , 0.85),\n",
    "    ('A17', 15 ,  8 , 'blue' ,'square'   , 0.60),\n",
    "    ('A23', 16 , 10 , 'blue' ,'circle'   , 0.30),\n",
    "    ('A24', 15 ,  5 , 'red'  ,'square'   , 0.60),\n",
    "]\n",
    "\n",
    "scene_img = build_scene_from_objects(objects_manual)\n",
    "\n",
    "# Plot, treinar e avaliar\n",
    "plot_scene({'coords': scene_img['coords'],\n",
    "            'shape_idx': scene_img['shape_idx'],\n",
    "            'color_idx': scene_img['color_idx'],\n",
    "            'size_idx': scene_img['size_idx']})\n",
    "\n",
    "models, history, forms, preds = train_scene(scene_img, epochs=220, lr=0.01)\n",
    "print(f\"satAgg final: {history[-1]:.4f}\")\n",
    "metrics_df = compute_metrics(preds, scene_img['labels'], threshold=THRESH)\n",
    "display(metrics_df)\n",
    "\n",
    "queries = composed_queries(preds)\n",
    "print({k: float(v) for k, v in queries.items()})\n",
    "explain_queries(scene_img, preds, threshold=0.6)\n",
    "\n",
    "formula_table = pd.DataFrame([{ 'formula': k, 'satisfacao': float(v) } for k, v in forms.items()])\n",
    "display(formula_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
